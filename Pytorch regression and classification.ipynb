{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torcheval"
      ],
      "metadata": {
        "id": "AhkWakfQhhD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6kot51b7nDo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import sklearn\n",
        "import torcheval\n",
        "from torcheval.metrics import R2Score\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x):\n",
        "  return (1+x)**(1/2)"
      ],
      "metadata": {
        "id": "IQ2ms7QZ7q5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) Computing random labels"
      ],
      "metadata": {
        "id": "5nB-KdXv8nWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N=10000\n",
        "xs=torch.rand(N)\n",
        "labels=f(xs)\n",
        "\n",
        "print(xs,\"\\n\",labels)"
      ],
      "metadata": {
        "id": "F6Sc9V-W75qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Closed form solution"
      ],
      "metadata": {
        "id": "Qmf7Iz4m8kVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=torch.concat((torch.ones(N).unsqueeze(1),xs.unsqueeze(1)), dim=1)\n",
        "print(\"X matrix\", X)\n",
        "\n",
        "w=(X.t()@X).inverse()@X.t()@labels\n",
        "print(\"Weights\", w)\n",
        "print(\"labels comparison\", X@w, labels)"
      ],
      "metadata": {
        "id": "6ne6wIxR8HUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "c) sklearn linear regression"
      ],
      "metadata": {
        "id": "pgR4z5Ba9u12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lin_reg =sklearn.linear_model.LinearRegression()\n",
        "lin_reg.fit(xs.unsqueeze(1), labels)\n",
        "y_pred=lin_reg.predict(xs.unsqueeze(1))\n",
        "\n",
        "print(\"Weights\", lin_reg.coef_)\n",
        "print(\"labels comparison\", y_pred, labels)\n",
        "print(sklearn.metrics.r2_score(labels,y_pred))"
      ],
      "metadata": {
        "id": "SIoMiwZx96Xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "d) Grad descent from scratch"
      ],
      "metadata": {
        "id": "9OfdAJ_Q_PYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xs.requires_grad=True\n",
        "X.requires_grad=True\n",
        "def gradient(x, y):\n",
        "  loss=(y**2-x**2).mean()\n",
        "  loss.backward()\n",
        "  return loss.item()"
      ],
      "metadata": {
        "id": "bIivnVp6CWdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "def gradient_descent():\n",
        "    weights = torch.randn(2, requires_grad=True)\n",
        "    lr = 0.1\n",
        "    metric = R2Score()\n",
        "\n",
        "    for i in range(200):\n",
        "        y_pred = X @ weights\n",
        "        loss = torch.mean((y_pred - labels) ** 2)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            weights -= lr * weights.grad\n",
        "            weights.grad.zero_()\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            metric.reset()\n",
        "            metric.update(y_pred.squeeze(), labels)\n",
        "            print(\"iteration\", i, \"R^2:\", metric.compute().item())\n",
        "    return weights\n",
        "\n",
        "weights = gradient_descent()\n"
      ],
      "metadata": {
        "id": "hfPONfeP-D17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "e) linear regression using pytorch"
      ],
      "metadata": {
        "id": "5LhBlZ8uDsox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegression(torch.nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super().__init__()\n",
        "    self.linear = torch.nn.Linear(input_dim, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)"
      ],
      "metadata": {
        "id": "diqaTTRX_eW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "linreg = LinearRegression(1,1)\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(linreg.parameters(), lr=0.001)\n",
        "\n",
        "metric = R2Score()\n",
        "\n",
        "for epoch in range(1000):\n",
        "  y_pred = linreg(xs.unsqueeze(1))\n",
        "  loss = criterion(y_pred, labels.unsqueeze(1))\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if epoch % 100 == 0:\n",
        "    metric.reset()\n",
        "    metric.update(y_pred, labels.unsqueeze(1))\n",
        "    print(f\"Epoch {epoch} R^2:\", metric.compute().item())"
      ],
      "metadata": {
        "id": "XMb13LQkEKEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "f) Mini batch from scratch"
      ],
      "metadata": {
        "id": "UMEmNHoOHy3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "linreg2 = LinearRegression(1,1)\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(linreg2.parameters(), lr=0.001)\n",
        "\n",
        "metric = R2Score()\n",
        "\n",
        "indices = torch.randperm(N)\n",
        "X_batches = torch.split(xs[indices], 32)\n",
        "labels_batches = torch.split(labels[indices], 32)\n",
        "\n",
        "for epoch in range(10):\n",
        "  for x, y in zip(X_batches, labels_batches):\n",
        "    x = x.detach()\n",
        "    y = y.detach()\n",
        "\n",
        "    y_pred = linreg2(x.unsqueeze(1))\n",
        "    loss = criterion(y_pred, y.unsqueeze(1))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  metric.reset()\n",
        "  metric.update(y_pred, y.unsqueeze(1))\n",
        "  print(f\"Epoch {epoch} R^2:\", metric.compute().item())"
      ],
      "metadata": {
        "id": "1hGEXNxGeCqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"closed form\", w)\n",
        "print(\"sklearn\", weights)\n",
        "print(\"scratch\", linreg.linear.weight)\n",
        "print(\"scratch mini batch\", linreg2.linear.weight)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "fig.set_figheight(10)\n",
        "fig.set_figwidth(10)\n",
        "xs_np=xs.detach().numpy()\n",
        "\n",
        "ax.scatter(xs_np, labels.detach().numpy(), alpha=0.01, s=10, label=\"original data\")\n",
        "\n",
        "taylor = np.sqrt(1+0.5) + (1/(2*np.sqrt(1+0.5))) * (xs_np - 0.5)\n",
        "ax.plot(xs_np, taylor, label=\"Taylor 1st order\", linestyle=\"--\", color=\"black\")\n",
        "\n",
        "ax.plot(xs_np, (X@w).detach().numpy(), label=\"closed form\", linestyle=\"-\", color=\"red\")\n",
        "\n",
        "ax.plot(xs_np, (X@weights).detach().numpy(), label=\"scratch\", linestyle=\":\", color=\"blue\")\n",
        "\n",
        "pytorch_full = (xs.unsqueeze(1) @ linreg.linear.weight.t() + linreg.linear.bias).detach().numpy().squeeze()\n",
        "ax.plot(xs_np, pytorch_full, label=\"pytorch full\", linestyle=\"-.\", color=\"green\")\n",
        "\n",
        "pytorch_mini = (xs.unsqueeze(1) @ linreg2.linear.weight.t() + linreg2.linear.bias).detach().numpy().squeeze()\n",
        "ax.plot(xs_np, pytorch_mini, label=\"pytorch mini-batch\", linestyle=\"--\", color=\"purple\")\n",
        "\n",
        "\n",
        "leg = ax.legend([\"original\", \"Taylor 1st order around 0.5\", \"closed form\", \"from scratch\", \"pytorch\", \"pytorch with mini batch from scratch\"])\n",
        "\n",
        "for lh in leg.legend_handles:\n",
        "    lh.set_alpha(1)\n",
        "    lh.set_linewidth(5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "biDOtIOXeRU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(x,y):\n",
        "  return ((x-y)**2).mean()\n",
        "\n",
        "def taylor(x,a):\n",
        "  return np.sqrt(1+a)+1/(2*np.sqrt(1+a))*(x-a)\n",
        "\n",
        "# compare with taylor\n",
        "print(\"original\", mse(taylor(xs_np, 0.5) , labels.detach().numpy()))\n",
        "print(\"closed form\", mse(taylor(xs_np, 0.5) , (X@w).detach().numpy()))\n",
        "print(\"from scratch\", mse(taylor(xs_np, 0.5) , (X@weights).detach().numpy()))\n",
        "print(\"pytorch\", mse(taylor(xs_np, 0.5) , (xs.unsqueeze(1)@linreg.linear.weight.t()+linreg.linear.bias).detach().numpy()))\n",
        "print(\"from scratch mini batch\", mse(taylor(xs_np, 0.5) , (xs.unsqueeze(1)@linreg2.linear.weight.t()+linreg2.linear.bias).detach().numpy()))\n"
      ],
      "metadata": {
        "id": "7XaXccgEkSx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART 2:\n",
        "a) download data, keep 20% for testing"
      ],
      "metadata": {
        "id": "CY91ng3OfGXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# upload dataset\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "phJzrsnD0xUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data=pd.read_csv(\"heart_disease_uci.csv\")\n",
        "y = (data.pop(\"num\") > 0).astype(int)\n",
        "\n",
        "# 2. Train/test split\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
        "    data, y, test_size=0.2, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "# 3. preprocessing pipeline\n",
        "numeric_features = X_train.select_dtypes(include=['int64','float64']).columns\n",
        "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
        "\n",
        "# I use only imputer here to remove NaNs, in this case without normalization\n",
        "numeric_transformer0 = sklearn.pipeline.Pipeline(steps=[\n",
        "    ('imputer', sklearn.impute.SimpleImputer(strategy='mean')),\n",
        "])\n",
        "\n",
        "categorical_transformer0 = sklearn.pipeline.Pipeline(steps=[\n",
        "    ('imputer', sklearn.impute.SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', sklearn.preprocessing.OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor0 = sklearn.compose.ColumnTransformer([\n",
        "    ('num', numeric_transformer0, numeric_features),\n",
        "    ('cat', categorical_transformer0, categorical_features)\n",
        "])\n",
        "\n",
        "# 4. Fit on training data, transform both\n",
        "X_train0 = preprocessor0.fit_transform(X_train)\n",
        "X_test0  = preprocessor0.transform(X_test)"
      ],
      "metadata": {
        "id": "WXlghw18fFEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Perform logistic regression and try to find the best hyperparameters (using sklearn)."
      ],
      "metadata": {
        "id": "l8acl2hrkIp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "# time now\n",
        "start = time.time()\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
        "    'max_iter': [100, 1000, 10000]\n",
        "}\n",
        "\n",
        "logreg = sklearn.linear_model.LogisticRegression(random_state=42)\n",
        "\n",
        "grid_search = sklearn.model_selection.GridSearchCV(logreg, param_grid, cv=5, n_jobs=-1)\n",
        "grid_search.fit(X_train0, y_train)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(\"convergence time\", end - start)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Best cross-val accuracy:\", grid_search.best_score_)\n",
        "print(\"Test accuracy:\", grid_search.score(X_test0, y_test))"
      ],
      "metadata": {
        "id": "rkXn-48ug8Hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "c) Normalize data and run logistic regression again"
      ],
      "metadata": {
        "id": "djrRFZ84rPxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv(\"heart_disease_uci.csv\")\n",
        "y = (data.pop(\"num\") > 0).astype(int)\n",
        "\n",
        "# 2. Train/test split\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
        "    data, y, test_size=0.2, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "# 3. preprocessing pipeline\n",
        "numeric_features = X_train.select_dtypes(include=['int64','float64']).columns\n",
        "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
        "\n",
        "numeric_transformer = sklearn.preprocessing.StandardScaler()\n",
        "categorical_transformer = sklearn.preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "numeric_transformer = sklearn.pipeline.Pipeline(steps=[\n",
        "    ('imputer', sklearn.impute.SimpleImputer(strategy='mean')),\n",
        "    ('scaler', sklearn.preprocessing.StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = sklearn.pipeline.Pipeline(steps=[\n",
        "    ('imputer', sklearn.impute.SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', sklearn.preprocessing.OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = sklearn.compose.ColumnTransformer([\n",
        "    ('num', numeric_transformer, numeric_features),\n",
        "    ('cat', categorical_transformer, categorical_features)\n",
        "])\n",
        "\n",
        "# 4. Fit on training data, transform both\n",
        "X_train = preprocessor.fit_transform(X_train)\n",
        "X_test  = preprocessor.transform(X_test)"
      ],
      "metadata": {
        "id": "x4ZalnSjfWbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
        "    'max_iter': [100, 1000, 10000]\n",
        "}\n",
        "\n",
        "logreg = sklearn.linear_model.LogisticRegression(random_state=42)\n",
        "\n",
        "grid_search = sklearn.model_selection.GridSearchCV(logreg, param_grid, cv=5, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "end = time.time()\n",
        "print(\"convergence time\", end - start)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Best cross-val accuracy:\", grid_search.best_score_)\n",
        "print(\"Test accuracy:\", grid_search.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "ikYsnhSBp-Pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From what we can see, though unnormalized data performed slightly better (0.853 against 0.847), it converged much slower (17 seconds against 0.5 seconds)"
      ],
      "metadata": {
        "id": "Ie2tom-trGL4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "d) Try to find the best neural net to solve this problem which will have no more than\n",
        "2 hidden layers (use sklearn). Without scaling"
      ],
      "metadata": {
        "id": "5k4Vk3wQtbBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_layer_sizes = []\n",
        "\n",
        "for i in range(3,8):\n",
        "  for j in range(3,8):\n",
        "    hidden_layer_sizes.append((2**i, 2**j))\n",
        "\n",
        "param_grid = {\n",
        "    'hidden_layer_sizes': hidden_layer_sizes\n",
        "}\n",
        "\n",
        "classifier = sklearn.neural_network.MLPClassifier(random_state=42, max_iter=100, early_stopping=True)\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "grid_search = sklearn.model_selection.GridSearchCV(classifier, param_grid, cv=3, n_jobs=-1)\n",
        "grid_search.fit(X_train0, y_train)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "results_df = pd.DataFrame(grid_search.cv_results_)\n",
        "sorted_df = results_df.sort_values(by=\"mean_test_score\", ascending=False)\n",
        "\n",
        "top5 = sorted_df[[\"mean_test_score\", \"params\"]].head(5)\n",
        "print(top5.to_string(index=False))\n",
        "\n",
        "print(\"convergence time\", end - start)\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Best cross-val accuracy:\", grid_search.best_score_)\n",
        "print(\"Test accuracy:\", grid_search.score(X_test0, y_test))"
      ],
      "metadata": {
        "id": "e1OEDsY5tYiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With normalization"
      ],
      "metadata": {
        "id": "05SL7tlQ0jtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = sklearn.neural_network.MLPClassifier(random_state=42, early_stopping=True)\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "grid_search = sklearn.model_selection.GridSearchCV(classifier, param_grid, cv=3, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "results_df = pd.DataFrame(grid_search.cv_results_)\n",
        "sorted_df = results_df.sort_values(by=\"mean_test_score\", ascending=False)\n",
        "\n",
        "top5 = sorted_df[[\"mean_test_score\", \"params\"]].head(5)\n",
        "print(top5.to_string(index=False))\n",
        "\n",
        "print(\"convergence time\", end - start)\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Best cross-val accuracy:\", grid_search.best_score_)\n",
        "print(\"Test accuracy:\", grid_search.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "Tby6E8n_vDhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's interesting how normalization totally changes the architecture. We can notice that data normalization makes large difference in accuracy for both accuracy (0.728 against 0.858) and convergence time (3.85 and 5.36). Also notice how un-normalized data prefers \"wider\" network (64,32), though (32,128) again performs well in top 5. A logical assummption can be made that first network is more adapted to extracting raw data. On the contrary, the second one has better data exploration given the data is already \"extracted\".  \n",
        "\n",
        "I have also tried changing learning-rate and activation function once, but because of long convergence time I changed the code. In short, smaller learning rates make small difference but not enough to trade-off with time. From sigmoid, tanh and relu, the best performer was always relu."
      ],
      "metadata": {
        "id": "_JfhfS0B0lyb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "f) using NN classifier with PyTorch (no more than 2 hidden layers)"
      ],
      "metadata": {
        "id": "Go8ubd-n02_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transforming numpy arrays to tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor), batch_size=32, shuffle=True)\n",
        "test_dataloader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_test_tensor, y_test_tensor), batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "DPvPijB4p-sO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(torch.nn.Module):\n",
        "  def __init__(self, in_ch, hidden1, hidden2, out_ch):\n",
        "    super().__init__()\n",
        "\n",
        "    self.nn = torch.nn.Sequential(\n",
        "        torch.nn.Linear(in_ch, hidden1), torch.nn.ReLU(),\n",
        "        torch.nn.Linear(hidden1, hidden2), torch.nn.ReLU(),\n",
        "        torch.nn.Linear(hidden2, out_ch), torch.nn.ReLU(),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.nn(x)"
      ],
      "metadata": {
        "id": "42Q-Gefb1BPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_classifier(hidden1, hidden2):\n",
        "  model = Classifier(X_train.shape[1], hidden1, hidden2, y_train.shape[0])\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  model.to(device)\n",
        "\n",
        "  loss_f = torch.nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "  num_epochs = 20\n",
        "\n",
        "  train_accuracy_last = 0\n",
        "  val_accuracy_last = 0\n",
        "\n",
        "  best_validation_score = 0\n",
        "  best_model = None\n",
        "  patience = 50\n",
        "  epochs_without_improvement=0\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      train_accuracy = []\n",
        "      val_accuracy = []\n",
        "\n",
        "      # train\n",
        "      model.train()\n",
        "      for batch in train_dataloader:\n",
        "        x, y = batch\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        y_pred = model(x)\n",
        "        loss = loss_f(y_pred, y.long())\n",
        "\n",
        "        train_accuracy.append(sklearn.metrics.f1_score(y.detach().cpu().numpy(), torch.argmax(y_pred, dim=1).detach().cpu().numpy(), average='weighted'))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "      train_accuracy_last = np.mean(train_accuracy)\n",
        "\n",
        "      # test\n",
        "      model.eval()\n",
        "\n",
        "      with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "          x, y = batch\n",
        "          x, y = x.to(device), y.to(device)\n",
        "          y_pred = model(x)\n",
        "          loss = loss_f(y_pred, y.long())\n",
        "\n",
        "          val_accuracy.append(sklearn.metrics.f1_score(y.detach().cpu().numpy(), torch.argmax(y_pred, dim=1).detach().cpu().numpy(), average='weighted'))\n",
        "\n",
        "        val_accuracy_last = np.mean(val_accuracy)\n",
        "\n",
        "      # early stopping\n",
        "      if val_accuracy_last > best_validation_score:\n",
        "        best_validation_score = val_accuracy_last\n",
        "        best_model = model.state_dict()\n",
        "        epochs_without_improvement=0\n",
        "      else:\n",
        "        epochs_without_improvement += 1\n",
        "        if epochs_without_improvement >= patience:\n",
        "          print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
        "          break\n",
        "\n",
        "  if best_model is not None:\n",
        "      model.load_state_dict(best_model)\n",
        "\n",
        "  # print(\"hidden layers: \", hidden1, hidden2, \"train accuracy\", train_accuracy_last, \"val accuracy\", val_accuracy_last)\n",
        "  return best_model, train_accuracy_last, val_accuracy_last"
      ],
      "metadata": {
        "id": "L0O_oQtK1OeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_validation = 0\n",
        "best_model = None\n",
        "best_hidden_layers=()\n",
        "\n",
        "results ={} # train accuracy, validation accuracy, training time\n",
        "\n",
        "for i in range(3,10):\n",
        "  for j in range(3,10):\n",
        "    train_start = time.time()\n",
        "    model, train_accuracy, val_accuracy = train_classifier(2**i, 2**j)\n",
        "    train_end = time.time()\n",
        "    if val_accuracy > best_validation:\n",
        "      best_validation = val_accuracy\n",
        "      best_model = model\n",
        "      best_hidden_layers=(2**i,2**j)\n",
        "    results[(2**i,2**j)] = (train_accuracy, val_accuracy, train_end-train_start)\n",
        "\n",
        "best_train = max(results.items(), key=lambda x: x[1][0])\n",
        "print(f\"Best training accuracy: {best_train[1][0]:.4f} at layers {best_train[0]}\")\n",
        "\n",
        "best_val = max(results.items(), key=lambda x: x[1][1])\n",
        "print(f\"Best validation accuracy: {best_val[1][1]:.4f} at layers {best_val[0]}\")\n",
        "\n",
        "fastest = min(results.items(), key=lambda x: x[1][2])\n",
        "print(f\"Fastest model: {fastest[1][2]:.2f}s at layers {fastest[0]}\")\n",
        "\n",
        "for layers, r in sorted(results.items(), key=lambda x: x[1][1], reverse=True):\n",
        "  print(f\"Layers: {layers}, Train accuracy: {r[0]:.4f}, Val accuracy: {r[1]:.4f}, Training time {r[2]:.4f}\")"
      ],
      "metadata": {
        "id": "OHi5PVAZ2UbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best training accuracy: (512, 64), Train accuracy: 0.9795, Val accuracy: 0.8630, Training time 4.1472.  \n",
        "\n",
        "Best validation accuracy: (8, 256), Train accuracy: 0.8906, Val accuracy: 0.8713, Training time 4.9603  \n",
        "\n",
        "Fastest model: (64, 16), Train accuracy: 0.3860, Val accuracy: 0.4425, Training time 2.7956.\n",
        "\n",
        "Sadly, as much as I tried to make an analysis of the results, most of the time they're quite different. For example, in one case I got the best validation accuracy being (64,8), which is the complete opposite of what we see now (8,256). This means that NN is highly dependent on the initial conditions. On the other hand, large first layer is almost always the best at training and thus at overfitting.  \n",
        "\n",
        "Though (64,16) had faster training rate, it's one of the worst performers."
      ],
      "metadata": {
        "id": "efdq0of73N5S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "g) Compare accuracies of all obtained models."
      ],
      "metadata": {
        "id": "7LPrGg3Q30Iv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# after finding out that (8, 256) performs the best\n",
        "# I runned several cases to find the best random initialization and avoid local minimums\n",
        "\n",
        "best_model = None\n",
        "best_val = 0.0\n",
        "for _ in range(10):\n",
        "  model, train_accuracy, validation_accuracy = train_classifier(8,256)\n",
        "  print(train_accuracy, validation_accuracy)\n",
        "  if validation_accuracy > best_val:\n",
        "    best_model=model\n",
        "    best_val = validation_accuracy\n",
        "\n",
        "print(best_val)"
      ],
      "metadata": {
        "id": "c2Js38khA7b7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Right now there are  \n",
        "\n",
        "1) logistic regression without normalization 0.853, time 28.06s  \n",
        "2) logistic regression with normalization 0.847, time 0.529s  \n",
        "3) scikit learn nn without normalization 0.809, time 7.0s  \n",
        "4) scikit learn nn with normalization 0.831, time 5.82s  \n",
        "5) pytorch best model 0.858, time 4.9s  \n",
        "\n",
        "Which is quite interesting that simple logistic regression with normalization performs almost as well as pytorch NN. We can also notice from this data that normalization increases convergence time in general."
      ],
      "metadata": {
        "id": "7s5syZaO9s6_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "h) Retrain your best-performing model using PyTorch Lightning. Incorporate a logger\n",
        "to track your experiments and use a learning rate scheduler."
      ],
      "metadata": {
        "id": "HWHyawIN_UVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightning as pl"
      ],
      "metadata": {
        "id": "bupuYDoI4Jb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LitClassifier(pl.LightningModule):\n",
        "    def __init__(self, input_size, hidden1, hidden2, output_size, lr=1e-2):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.model = torch.nn.Sequential(\n",
        "            torch.nn.Linear(input_size, hidden1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(hidden1, hidden2),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(hidden2, output_size)\n",
        "        )\n",
        "        self.loss_f = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x.float())\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=0.01)\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "        return [optimizer], [scheduler]\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_pred = self(x)\n",
        "        loss = self.loss_f(y_pred, y.long())\n",
        "        preds = torch.argmax(y_pred, dim=1)\n",
        "        acc = sklearn.metrics.f1_score(y.cpu(), preds.cpu(), average='weighted')\n",
        "        self.log(\"train_loss\", loss, prog_bar=True)\n",
        "        self.log(\"train_f1\", acc, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_pred = self(x)\n",
        "        loss = self.loss_f(y_pred, y.long())\n",
        "        preds = torch.argmax(y_pred, dim=1)\n",
        "        acc = sklearn.metrics.f1_score(y.cpu(), preds.cpu(), average='weighted')\n",
        "        self.log(\"val_loss\", loss, prog_bar=True)\n",
        "        self.log(\"val_f1\", acc, prog_bar=True)\n"
      ],
      "metadata": {
        "id": "BIS-2eAsAJE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pl_model = LitClassifier(X_train.shape[1], 8, 256, y_train.shape[0])\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=25,\n",
        "    logger=pl.pytorch.loggers.tensorboard.TensorBoardLogger(save_dir=\"logs/\"),\n",
        "    callbacks=[pl.pytorch.callbacks.ModelCheckpoint(monitor=\"val_f1\", mode=\"max\")],\n",
        "    deterministic=True\n",
        ")\n",
        "\n",
        "trainer.fit(pl_model, train_dataloader, test_dataloader)\n"
      ],
      "metadata": {
        "id": "jFHMjfsVA3u-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lightning model achieved 0.85 validation accuracy"
      ],
      "metadata": {
        "id": "CUveU1R3Eufd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kOeURwfjDWb1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
