{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP5fKZKX4HCyeTee6ubrMG5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import torch"],"metadata":{"id":"uEVrpUpHltYl"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QEHI_kjtlMjC"},"outputs":[],"source":["import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision.datasets import CIFAR100\n","from torchvision import transforms\n","from tqdm import tqdm"]},{"cell_type":"code","source":["train_dataset=CIFAR100(\"./CIFAR100\", download=True, transform=transforms.ToTensor())\n","test_dataset=CIFAR100(\"./CIFAR100\", train=False, transform=transforms.ToTensor())"],"metadata":{"id":"pKMhbS8Bl2Rp","executionInfo":{"status":"ok","timestamp":1747562808740,"user_tz":-240,"elapsed":6853,"user":{"displayName":"RaZZaZo","userId":"07466042586190014139"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"65a529c0-9dbf-4b09-b642-ece540925002"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 169M/169M [00:03<00:00, 47.0MB/s]\n"]}]},{"cell_type":"code","source":["model = nn.Sequential(\n","    nn.Conv2d(3, 64, 3, padding=\"same\"), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n","    nn.MaxPool2d((2, 2), stride=2),\n","\n","    nn.Conv2d(64, 128, 3, padding=\"same\"), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n","\n","    nn.Conv2d(128, 256, 3, padding=\"same\"), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n","    nn.Dropout2d(),\n","\n","    nn.Conv2d(256, 256, 3, padding=\"same\"), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n","\n","    nn.Conv2d(256, 128, 3, padding=\"same\"), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n","    nn.MaxPool2d((2, 2), stride=2),\n","\n","    nn.Conv2d(128, 64, 3, padding=\"same\"), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n","\n","    nn.Flatten(),\n","    nn.Linear(4096, 256),\n","    nn.Dropout2d(),\n","    nn.ReLU(),\n","    nn.Linear(256, 100),\n",")"],"metadata":{"id":"fgd_t-rql5f5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device=torch.device(\"cuda\")\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DTKgHAr_-dpm","executionInfo":{"status":"ok","timestamp":1747568394018,"user_tz":-240,"elapsed":16,"user":{"displayName":"RaZZaZo","userId":"07466042586190014139"}},"outputId":"aaec46b6-ecce-45d0-bc3f-fe12c0878938"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n","  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (2): ReLU(inplace=True)\n","  (3): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n","  (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (6): ReLU(inplace=True)\n","  (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n","  (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (9): ReLU(inplace=True)\n","  (10): Dropout2d(p=0.5, inplace=False)\n","  (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n","  (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (13): ReLU(inplace=True)\n","  (14): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n","  (15): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (16): ReLU(inplace=True)\n","  (17): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (18): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n","  (19): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (20): ReLU(inplace=True)\n","  (21): Flatten(start_dim=1, end_dim=-1)\n","  (22): Linear(in_features=4096, out_features=256, bias=True)\n","  (23): Dropout2d(p=0.5, inplace=False)\n","  (24): ReLU()\n","  (25): Linear(in_features=256, out_features=100, bias=True)\n",")"]},"metadata":{},"execution_count":241}]},{"cell_type":"code","source":["g = torch.Generator(device='cuda')\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, generator=g)\n","test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True, generator=g)\n","\n","lossfn = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr = 0.001)\n","\n","for epoch in range(100):\n","  model.train()\n","  running_correct = 0\n","  running_total = 0\n","\n","  for batch in tqdm(train_dataloader):\n","      optimizer.zero_grad()\n","      x, y = batch\n","      x, y = x.to(device), y.to(device)\n","      outputs = model(x)\n","      loss = lossfn(outputs, y)\n","\n","      l2_lambda = 0.001\n","      l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n","      loss = loss + l2_lambda * l2_norm\n","\n","      loss.backward()\n","      optimizer.step()\n","\n","      # Accumulate training accuracy\n","      _, predicted = torch.max(outputs.data, 1)\n","      running_total += y.size(0)\n","      running_correct += (predicted == y).sum().item()\n","\n","  train_accuracy = 100 * running_correct / running_total\n","\n","  print(f\"Epoch: {epoch}, train Loss: {loss.item()}, train accuracy: {train_accuracy:.2f}%\")\n","\n","  model.eval()\n","  running_correct = 0\n","  running_total = 0\n","\n","  with torch.no_grad():\n","      for batch in tqdm(test_dataloader):\n","          x, y = batch\n","          x, y = x.to(device), y.to(device)\n","          outputs = model(x)\n","          loss = lossfn(outputs, y)\n","\n","          _, predicted = torch.max(outputs.data, 1)\n","          running_total += y.size(0)\n","          running_correct += (predicted == y).sum().item()\n","\n","  test_accuracy = 100 * running_correct / running_total\n","  print(f\"Epoch: {epoch}, test Loss: {loss.item()}, test accuracy: {test_accuracy:.2f}%\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":717},"id":"EX4v_axo0h4o","executionInfo":{"status":"error","timestamp":1747569356872,"user_tz":-240,"elapsed":128734,"user":{"displayName":"RaZZaZo","userId":"07466042586190014139"}},"outputId":"57f13cac-9c7b-4fe3-f273-b846c8680d50"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/782 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1538: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n","  warnings.warn(warn_msg)\n","100%|██████████| 782/782 [00:23<00:00, 33.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, train Loss: 4.250352382659912, train accuracy: 19.89%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:02<00:00, 67.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, test Loss: 3.891636848449707, test accuracy: 28.27%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 782/782 [00:23<00:00, 33.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, train Loss: 4.302264213562012, train accuracy: 21.48%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:02<00:00, 67.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, test Loss: 3.4822890758514404, test accuracy: 29.09%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 782/782 [00:23<00:00, 32.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, train Loss: 3.96451997756958, train accuracy: 22.29%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:02<00:00, 67.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, test Loss: 3.485367774963379, test accuracy: 30.01%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 782/782 [00:23<00:00, 32.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 3, train Loss: 3.47640323638916, train accuracy: 23.26%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:02<00:00, 67.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 3, test Loss: 3.067741632461548, test accuracy: 31.27%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 782/782 [00:23<00:00, 33.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 4, train Loss: 4.715912818908691, train accuracy: 24.32%\n"]},{"output_type":"stream","name":"stderr","text":[" 38%|███▊      | 59/157 [00:01<00:01, 58.03it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-243-18c6987d224d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m           \u001b[0mrunning_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m           \u001b[0mrunning_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrunning_correct\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrunning_total\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_device.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_device_constructors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;31m# NB: This is directly called from C++ in torch/csrc/Device.cpp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["#   0%|          | 0/782 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1538: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n","#   warnings.warn(warn_msg)\n","# 100%|██████████| 782/782 [00:23<00:00, 32.94it/s]\n","\n","# Epoch: 0, train Loss: 4.758344650268555, train accuracy: 10.99%\n","\n","# 100%|██████████| 157/157 [00:02<00:00, 54.11it/s]\n","\n","# Epoch: 0, test Loss: 3.5926952362060547, test accuracy: 23.94%\n","\n","# 100%|██████████| 782/782 [00:23<00:00, 32.69it/s]\n","\n","# Epoch: 1, train Loss: 4.341193199157715, train accuracy: 23.60%\n","\n","# 100%|██████████| 157/157 [00:02<00:00, 66.27it/s]\n","\n","# Epoch: 1, test Loss: 3.2581331729888916, test accuracy: 34.37%\n","\n","# 100%|██████████| 782/782 [00:23<00:00, 33.12it/s]\n","\n","# Epoch: 2, train Loss: 3.701869010925293, train accuracy: 31.73%\n","\n","# 100%|██████████| 157/157 [00:02<00:00, 66.88it/s]\n","\n","# Epoch: 2, test Loss: 2.703483819961548, test accuracy: 37.41%\n","\n","# 100%|██████████| 782/782 [00:23<00:00, 33.14it/s]\n","\n","# Epoch: 3, train Loss: 3.049783229827881, train accuracy: 37.47%\n","\n","# 100%|██████████| 157/157 [00:02<00:00, 66.67it/s]\n","\n","# Epoch: 3, test Loss: 2.194138288497925, test accuracy: 44.80%\n","\n","# 100%|██████████| 782/782 [00:23<00:00, 32.77it/s]\n","\n","# Epoch: 4, train Loss: 3.9603524208068848, train accuracy: 42.33%\n","\n","# 100%|██████████| 157/157 [00:02<00:00, 64.89it/s]\n","\n","# Epoch: 4, test Loss: 2.2496135234832764, test accuracy: 47.39%\n","\n","# 100%|██████████| 782/782 [00:23<00:00, 32.98it/s]\n","\n","# Epoch: 5, train Loss: 3.1045172214508057, train accuracy: 45.66%\n","\n","# 100%|██████████| 157/157 [00:02<00:00, 66.79it/s]\n","\n","# Epoch: 5, test Loss: 1.4738649129867554, test accuracy: 49.08%\n","\n","# 100%|██████████| 782/782 [00:23<00:00, 32.97it/s]\n","\n","# Epoch: 6, train Loss: 2.946915626525879, train accuracy: 48.92%\n","\n","# 100%|██████████| 157/157 [00:02<00:00, 55.03it/s]\n","\n","# Epoch: 6, test Loss: 1.9509754180908203, test accuracy: 50.07%\n","\n","# 100%|██████████| 782/782 [00:23<00:00, 33.37it/s]\n","\n","# Epoch: 7, train Loss: 2.4504878520965576, train accuracy: 51.62%\n","\n","# 100%|██████████| 157/157 [00:02<00:00, 62.45it/s]\n","\n","# Epoch: 7, test Loss: 2.3012735843658447, test accuracy: 50.19%\n","\n","# 100%|██████████| 782/782 [00:23<00:00, 33.10it/s]\n","\n","# Epoch: 8, train Loss: 2.379197597503662, train accuracy: 54.47%\n","\n","# 100%|██████████| 157/157 [00:02<00:00, 67.65it/s]\n","\n","# Epoch: 8, test Loss: 1.0628859996795654, test accuracy: 51.94%\n","\n","# 100%|██████████| 782/782 [00:23<00:00, 33.25it/s]\n","\n","# Epoch: 9, train Loss: 2.4079670906066895, train accuracy: 56.83%\n","\n","# 100%|██████████| 157/157 [00:02<00:00, 67.19it/s]\n","\n","# Epoch: 9, test Loss: 1.9797344207763672, test accuracy: 53.42%\n","\n","# 100%|██████████| 782/782 [00:23<00:00, 33.06it/s]\n","\n","# Epoch: 10, train Loss: 2.0972490310668945, train accuracy: 59.01%\n","\n","# 100%|██████████| 157/157 [00:02<00:00, 67.71it/s]\n","\n","# Epoch: 10, test Loss: 1.8001538515090942, test accuracy: 54.24%\n","\n","# 100%|██████████| 782/782 [00:23<00:00, 32.91it/s]\n","\n","# Epoch: 11, train Loss: 1.7727878093719482, train accuracy: 61.19%\n","\n","# 100%|██████████| 157/157 [00:02<00:00, 66.85it/s]\n","\n","# Epoch: 11, test Loss: 2.0373265743255615, test accuracy: 54.34%\n","\n","# 100%|██████████| 782/782 [00:23<00:00, 32.95it/s]\n","\n","# Epoch: 12, train Loss: 1.674553394317627, train accuracy: 63.52%\n","\n","# 100%|██████████| 157/157 [00:02<00:00, 59.33it/s]\n","\n","# Epoch: 12, test Loss: 1.6343984603881836, test accuracy: 53.32%\n","\n","# 100%|██████████| 782/782 [00:23<00:00, 33.28it/s]\n","\n","# Epoch: 13, train Loss: 2.1454408168792725, train accuracy: 65.49%\n","\n","# 100%|██████████| 157/157 [00:02<00:00, 57.03it/s]\n","\n","# Epoch: 13, test Loss: 1.635261058807373, test accuracy: 56.02%\n","\n","# 100%|██████████| 782/782 [00:23<00:00, 32.97it/s]\n","\n","# Epoch: 14, train Loss: 1.543928623199463, train accuracy: 67.55%\n","\n","# 100%|██████████| 157/157 [00:02<00:00, 67.44it/s]\n","\n","# Epoch: 14, test Loss: 2.2715306282043457, test accuracy: 55.30%\n","\n","# 100%|██████████| 782/782 [00:23<00:00, 33.12it/s]\n","\n","# Epoch: 15, train Loss: 2.1259913444519043, train accuracy: 69.81%\n","\n","# 100%|██████████| 157/157 [00:02<00:00, 67.10it/s]\n","\n","# Epoch: 15, test Loss: 2.810858726501465, test accuracy: 54.66%\n","\n","# 100%|██████████| 782/782 [00:23<00:00, 33.15it/s]\n","\n","# Epoch: 16, train Loss: 2.4269018173217773, train accuracy: 71.82%\n","\n","# 100%|██████████| 157/157 [00:02<00:00, 66.56it/s]\n","\n","# Epoch: 16, test Loss: 1.3604072332382202, test accuracy: 55.59%\n","\n","# 100%|██████████| 782/782 [00:23<00:00, 33.16it/s]\n","\n","# Epoch: 17, train Loss: 2.133638381958008, train accuracy: 73.36%\n","\n","# 100%|██████████| 157/157 [00:02<00:00, 66.96it/s]\n","\n","# Epoch: 17, test Loss: 1.3773679733276367, test accuracy: 55.00%\n","\n","# 100%|██████████| 782/782 [00:23<00:00, 33.02it/s]\n","\n","# Epoch: 18, train Loss: 1.6365013122558594, train accuracy: 75.35%\n","\n","# 100%|██████████| 157/157 [00:02<00:00, 64.63it/s]\n","\n","# Epoch: 18, test Loss: 1.736431360244751, test accuracy: 54.71%\n","\n","# 100%|██████████| 782/782 [00:23<00:00, 33.10it/s]\n","\n","# Epoch: 19, train Loss: 1.7056007385253906, train accuracy: 76.93%\n","\n","# 100%|██████████| 157/157 [00:02<00:00, 53.85it/s]\n","\n","# Epoch: 19, test Loss: 1.4214465618133545, test accuracy: 55.20%\n","\n","# 100%|██████████| 782/782 [00:23<00:00, 33.00it/s]\n","\n","# Epoch: 20, train Loss: 1.5306720733642578, train accuracy: 79.16%\n","\n","# 100%|██████████| 157/157 [00:02<00:00, 66.84it/s]\n","\n","# Epoch: 20, test Loss: 1.4956436157226562, test accuracy: 55.41%\n","\n","# 100%|██████████| 782/782 [00:23<00:00, 33.04it/s]\n","\n","# Epoch: 21, train Loss: 1.6582317352294922, train accuracy: 80.61%\n","\n","# 100%|██████████| 157/157 [00:02<00:00, 66.28it/s]\n","\n","# Epoch: 21, test Loss: 1.8348461389541626, test accuracy: 55.16%\n","\n","#  30%|██▉       | 234/782 [00:07<00:16, 32.92it/s]\n"],"metadata":{"id":"NHi2XDc82n5_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"di3FIckeMX5h"},"execution_count":null,"outputs":[]}]}